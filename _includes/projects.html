<style>
    .title {
        height: 41px;
        padding: 7px 0px 0px 30px;
        letter-spacing: -.5px;
    }

    .entry {
        padding-bottom: 20px;
        text-align: justify;
    }

</style>



<div class="entry" id="evizeon">
    <h1><a href="https://research.tableau.com/sites/default/files/VAST2017_105.pdf">Natural Language Interactions with Visual Analytics</a></h1><br>
    <div style="text-align: center">

        <a href="https://research.tableau.com/sites/default/files/VAST2017_105.pdf"><img style="border:2px solid gray" src="{{ '/images/1.png' | relative_url }}" width="600"></a>
    </div>
    <p>Interactive visual data analysis is most productive when users can focus on answering the questions they have about their
        data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive
        conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more
        expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied
        to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics
        support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.
    </p>

    <h4 class="title"> Publications:
        <a href="https://research.tableau.com/sites/default/files/VAST2017_105.pdf">IEEE TVCG (Proc. VAST) 2017</a>,
        <a href="https://dhkim16.github.io/vis-qa/pdf/paper.pdf">ACM CHI 2020</a>
    </h4>
    <p></p>

</div>

<hr>

<div class="entry" id="convis">
    <h1><a href="https://www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/ConVis.html">Visual Text Analytics for Asynchronous Online Conversations</a></h1><br>
    <div style="text-align: center">
        <a href="https://www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/ConVis.html">
        <img style="border:2px solid gray" src="{{ '/images/3.jpg' | relative_url }}" width="600"></a>
    </div>
    <p>Since the rise of social-media, an ever-increasing amount of conversations are generated.
        Often many people contribute to the discussion, which become very long
        with hundreds of comments, making it difficult for users to get insights about the
        discussion. My PhD dissertation integrates language processing and visualization techniques
        to support the user’s task of exploring and analyzing conversations. Language
        processing mines topics and opinions from the conversations, while visualization
        techniques provide visual overviews of the mined data and support user
        exploration and analysis. User studies revealed significant improvements, when
        our systems were compared to traditional blog interfaces. This dissertation also
        introduces a new human-in-the-loop algorithm that helps the user to revise results
        of topic modeling. Two user studies show that these systems outperform their
        non-interactive counterparts. Finally, we tailored our previous systems to support
        information seeking in community question answering forums. The prototype was
        successfully evaluated through a large-scale user study.
    </p>

    <h4 class="title"> Publications:
        <a href="http://dl.acm.org/citation.cfm?id=2856782">IUI 16</a>,
        <a href="http://dl.acm.org/citation.cfm?id=2854158">TIIS 16</a>,
        <a href="http://www.cs.ubc.ca/~enamul/papers/IUI2015_ConVisIT.pdf">IUI 15</a>, <a href="http://www.cs.ubc.ca/~enamul/papers/ConVis_EuroVis2014.pdf">EuroVis 14</a>
    </h4>


</div>

<hr>

<div class="entry" id="atuav">
    <h1><a href="https://www.cs.ubc.ca/group/iui/ATUAV/index.html">User-Adaptive Information Visualization</a></h1><br>
    <div style="text-align: center">
    <img style="border:2px solid gray" src="{{ '/images/valuecharts.png' | relative_url }}" width="700">
    </div>
    <p>There is increasing evidence that user characteristics can have a significant impact on visualization effectiveness, suggesting that visualizations could be designed to better fit each user’s specific needs. Most studies to date, however, have looked at static visualizations. Studies considering interactive visualizations have only looked at a limited number of user characteristics, and consider either low-level tasks (e.g., value retrieval), or high-level tasks (in particular: discovery), but not both. This paper contributes to this line of work by looking at the impact of a large set of user characteristics on user performance with interactive visualizations, for both low and high-level tasks. We focus on interactive visualizations that support decision-making, exemplified by a visualization known as Value Charts. We include in the study two versions of ValueCharts that differ in layout, to ascertain whether layout mediates the impact of individual differences and could be considered as a form of personalization. Our  key findings are that (i)  performance with low and high-level tasks is affected by different user characteristics (ii) users with low visual working memory perform better with a horizontal layout. We discuss how these findings can inform the provision of personalized support to visualization processing.</p>
    <h4 class="title"> Publications
        <a href="http://www.cs.ubc.ca/~conati/my-papers/CHI-2014.pdf">CHI 14</a>,
        <a href="http://www.cs.ubc.ca/~conati/my-papers/EuroVis14.pdf">EuroVis 14</a>
    </h4>
</div>


<hr>

<div class="entry" id="cider">

    <h1>Concept-based image search and exploration</h1>
    <br>
    <div style="text-align: center">
        <img style="border:2px solid gray" src="{{ '/images/project.jpg' | relative_url }}" width="400">
    </div>
    <p>
    Even though Web image search queries are often ambiguous, traditional search
    engines promote only the most common interpretations of the query, which makes it
    diﬃcult for the searcher to ﬁnd the desired images. For addressing this problem, a
    concept-based query expansion technique is used to generate a diverse range of images
    covering multiple interpretations of the query. Then, a multi-resolution extension of
    a Self-Organizing Map is used to group conceptually and visually similar images.<br>

    The resulting interface allows
    the searcher to interactively highlight and ﬁlter images based on the concepts and
    zoom into an area within the image space to show additional images that are similar.
    Finally, a query reﬁnement approach is proposed, which enables enhancement of
    queries based on explicitly selecting concepts or extracting concepts from example
    images. A series of evaluations illustrate the potential beneﬁts of the system.  <br><br>

    </p><h4 class="title"> Publications:
        <a href="http://www.sciencedirect.com/science/article/pii/S0306457312001392">IPM 2011</a>,
        <a href="http://www.cs.ubc.ca/~enamul/papers/2011_awic_cqe.pdf">AWIC 2011</a>,
        <a href="http://www.cs.ubc.ca/~enamul/papers/2010_isvc_vibe_concept.pdf">ISVC 10</a>
    </h4><h4 class="title"> Video:
        <a href="http://www.youtube.com/embed/qS-MTcI6n1Q">Youtube</a>
    </h4>
</div>
